# WWM Default parameters

#&PROC
procname : 'schism_wwm_2003_test' # Project Name
dimmode  : 2 # Mode of run (ex: 1 = 1D, 2 = 2D) always 2D when coupled to SCHISM
lstea    : F # steady mode; under development
lqstea   : F # Quasi-Steady Mode; In this case WWM-II is doing subiterations defined as DELTC/NQSITER unless QSCONVI is not reached
lsphe    : T # Spherical coordinates (lon/lat)
lnautin  : T # Nautical convention for all inputs given in degrees 

lnautout : T # Output in Nautical convention 
             # If T, 0 is _from_ north, 90 is from east etc;
             # If F, maths. convention - 0: to east; 90: going to north
     
                        
lmono_in  : F # For prescribing monochromatic wave height Hmono as a boundary conditions; incident wave is defined as monochromatic wave height, which is Hmono = sqrt(2) * Hs
lmono_out : F # Output wave heights in terms of Lmono
begtc     : '20111101.000000'  # Time for start the simulation, ex:yyyymmdd. hhmmss
deltc     : 240                # Time step (MUST match dt*nstep_wwm in SCHISM)
unitc     : 'SEC'              # Unity of time step
endtc     : '20111125.000000'  # Time for stop the simulation, ex:yyyymmdd. hhmmss
dmin      : 0.1                # Minimum water depth. THis must be same as h0 in SCHISM


#-----------------------------------------------------------------------
# Coupling
#-----------------------------------------------------------------------

#&COUPL
lcpl    : T # Couple with current model ... main switch - keep it on for SCHISM-WWM
lroms   : F # ROMS (set as F)
ltimor  : F # TIMOR (set as F)
lshyfem : F # SHYFEM (set as F)
radflag : 'LON' # LON: Longuet-Higgin; VOR: vortex formulation
           
letot   : F # Option to compute the wave induced radiation stress. If .T. the radiation stress is based on the integrated wave spectrum
            # e.g. Etot = Int,0,inf;Int,0,2*pi[N(sigma,theta)]dsigma,dtheta. If .F. the radiation stress is estimated as given in Roland et al. (2008) based
            # on the directional spectra itself. It is always desirable to use .F., since otherwise the spectral informations are truncated and therefore
            # LETOT = .T., is only for testing and developers!


nlvt     : 10   # Number of vertical Layers; not used with SCHISM
dtcoup   : 600. # Couple time step - not used when coupled to SCHISM
imet_dry : 0

#-----------------------------------------------------------------------
# Computational grid
#-----------------------------------------------------------------------

#&GRID
lcird      : T                  # Full circle in directional space
lstag      : F                  # Stagger directional bins with a half Dtheta; may use T only for regular grid to avoid char. line aligning with grid line
mindir     : 0.                 # Minimum direction for simulation (unit: degrees; nautical convention; 0: from N; 90: from E); not used if LCIRD = .T.
maxdir     : 360.               # Maximum direction for simulation (unit: degrees); may be < MINDIR; not used if LCIRD = .T.
numdir     : 24                 # Number of directional bins
frlow      : 0.02               # Low frequency limit of the discrete wave period (Hz; 1/period)
frhigh     : 0.5                # High frequency limit of the discrete wave period.
numsig     : 21                 # Number of frequency bins
filegrid   : 'hgrid.gr3'        # Name of the grid file. hgrid.gr3 if IGRIDTYPE = 3 (SCHISM)
igridtype  : 3                  # Gridtype used.
                                # 1 ~ XFN system.dat
                                # 2 ~ WWM-PERIODIC
                                # 3 ~ SCHISM
                                # 4 ~ old WWM type 

lslop           : F             # Bottom Slope limiter (default=F)
slmax           : 0.2           # Max Slope;
lvar1d          : F             # For 1d-mode if variable dx is used; not used with SCHISM
loptsig         : F             # Use optimal distributions of freq. in spectral space ... fi+1 = fi * 1.1. Take care what you high freq. limit is!
cart2latlon     : F
latlon2cart     : F
apply_dxp_corr  : F
use_exact_formula_spherical_area : T # Use spherical formular for triangle area computation.
lexport_grid_mod_out             : F

#!-----------------------------------------------------------------------
#! Model Initialization
#!-----------------------------------------------------------------------

#&INIT
lhotr      : F                 # Use hotstart file (see &HOTFILE section)
linid      : T                 # Initial condition; F for default; use T if using WW3 as i.c. etc
initstyle  : 1                 # 1 - Parametric Jonswap, 2 - Read from Global NETCDF files, work only if IBOUNDFORMAT=2


#!-----------------------------------------------------------------------
#! Boundary Conditions
#!-----------------------------------------------------------------------

#&BOUC
lbcse     : T                  # The wave boundary data is time dependent
lbcwa     : T                  # Parametric Wave Spectra
lbcsp     : F                  # Specify (non-parametric) wave spectra, specified in 'FILEWAVE' below
linhom    : T                  # Non-uniform wave b.c. in space
lbsp1d    : F                  # 1D (freq. space only) format for FILEWAVE if LBCSP=T and LINHOM=F                    
lbsp2d    : F                  # Not used now 
lbinter   : T                  # Do interpolation in time if LBCSE=T (not available for quasi-steady mode within the subtime steps)
begtc     : '20111101.000000'  # Begin time of the wave boundary file (FILEWAVE) 
deltc     : 3                  # Time step in FILEWAVE 
unitc     : 'HR'               # Unit can be HR, MIN, SEC 
endtc     : 20111231.210000'   # End time
filebound : 'wwmbnd.gr3'       # Boundary file defining boundary conditions and Neumann nodes.
                               # In this file there is following definition Flag 0: not on boundary; 3: Neumann (0 gradient only for advection part);
                               # 2: active bnd (Dirichlet). Bnd flags imported from SCHISM: ! 1: exterior bnd; -1: interior (islands)
                               # exterio and interior boundaries need not to be defined.

iboundformat : 2                  # 1 ~ WWM, 2 ~ WW3. WW3 works only with LBCWA=T.
filewave     : 'bndfiles.dat'     # Boundary file defining boundary input
lindsprdeg   : F                  # If 1-d wave spectra are read this flag defines whether the input for the directional spreading is in degrees (true) or exponent (false)
lparmdir     : F                  # If LPARMDIR is true then directional spreading is read from WBDS and must be in exponential format at this time, only valid for 1d Spectra
                                  # For WW3 boundary input also set LINHOM=T, LBCSE=T and this works only for spherical coordinates

wbhs : 2.                         # Hs at the boundary for parametric spectra
wbss : 2                          # 1 or -1: Pierson-Moskowitz, 2 or -2: JONSWAP, 3 or -3: all in one BIN,
                                  # 4: Gauss. The sign decides whether WBTP below is
                                  # peak (+) or mean period (-)

wbtp    : 8.                      # Tp at the boundary (sec); mean or peak depending on the sign of WBSS
wbdm    : 90.0                    # Avg. Wave Direction at the boundary
wbdsms  : 1                       # Directional spreading value in degrees (1) or as exponent (2)
wbds    : 10.                     # Directioanl spreading at the boundary (degrees/exponent)
wbgauss : 0.1                     # factor for gaussian distribution if WBSS=1
                                  # End section for LBCWA=T and LINHOM=F

wbpken      : 3.3                # Peak enhancement factor for Jonswap Spectra if WBSS=2
multiple_in : T
netcdf_out_param      : F
netcdf_out_spectra    : F
netcdf_out_file       : 'boundary_out_spec.nc' 
use_single_out        : T
begtc_out             : 20111101.000000
deltc_out             : 600.000000000000
unitc_out             : 'SEC'
endtc_out             : 20111130.000000
extrapolation_allowed : F
hack_hard_set_iobp    : F
paramwrite            : T
netcdf_in_file        : 'bndfiles.dat'  
lexport_bouc_mod_out  : F
export_bouc_deltc     :  0.00


#!-----------------------------------------------------------------------
#! Wind forcing parameters
#!-----------------------------------------------------------------------

#&WIND ! THIS IS NOW USED IN SCHISM
lsewd       : F                  # Time dependend wind input
begtc       : '20111101.000000'  # Begin time
deltc       : 60.0               # Time step
unitc       : 'MIN'              # Unit
endtc       : '20111130.000000'  # End time
linterwd    : T                  # Interpolate linear within the wind input time step
lstwd       : T                  # Steady wind
lcwin       : T                  # Constant wind
lwdir       : T                  # Define wind using wind direction rather than vel. vectors
wdir        : 140.0              # Wind direction if LWDIR=T
wvel        : 10.0               # Wind velocity ...
cwindx      : 30.0               # wind x-vec if LWDIR=F
cwindy      : 0.0                # wind y-vec
filewind    : 'wind.dat'         # wind input data file; input file format: write(*,*) curtx; write(*,*) curty               
windfac     : 1.                 # Factor for wind scaling

iwindformat : 1  # kind of wind input
                 # 1 - ASCII,
                 # 2 - DWD_NETCDF
                 # 3 - NOAA CFRS
                 # 4 - NOAA NARR
                 # 5 - netCDF WRF/ROMS forcing (Uwind,Vwind,LON,LAT,wind_time are used), fast bilinear interp 

lwindfromwwm   : F # Wind is coming from WWM (true) or from SCHISM(false). This is under developement. If F, the following parameters in this section are ignored. For SCHISM users, use F. 
grib_file_type : 1
extrapolation_allowed : F
use_steprange         : T
multiple_in           : T
lexport_wind_mod_out  : F
export_wind_deltc     : 0.00
lsave_interp_array    : F 


#-----------------------------------------------------------------------
# Current forcing paramters
#-----------------------------------------------------------------------

#&CURR !NOT USED WITH SCHISM
lsecu    : F                  # Time dependend currents
begtc    : '20111101.000000'  # Begin time
deltc    : 600                # Time step
unitc    : 'SEC'              # Unit
endtc    : '20111130.000000'  # End time
lintercu : F                  # Interpolate linear within the wind input time step
lstcu    : F                  # Steady current
lccur    : F                  # Constant current
ccurtx   : 0.0                # current x-vec
ccurty   : 0.0                # current y-vec
filecur  : 'current.dat'      # Current file name; input file format: write(*,*) curtx; write(*,*) curty
lerginp  : F                  # read timor file for input ... ergzus.bin
curfac      : 1.000000
icurrformat : 1
multiple_in : T
lexport_curr_mod_out : F
export_curr_deltc    :  0.000000000000000E+000


#!-----------------------------------------------------------------------
#! ???
#!-----------------------------------------------------------------------

#&WALV !NOT USED WITH SCHISM
lsewl    : F                  # Time dependend elev.
begtc    : '20111101.000000'  # Begin time
deltc    : 1                  # Time step
unitc    : 'HR'               # Unit
endtc    : '20111130.000000'  # End time
linterwl : F                  # Interpolate linear within the wind input time step
lstwl    : T                  # Steady water level
lcwlv    : T                  # Constant water level
cwatlv   : 0.0                # elevation of the water level [m]
filewatl : ' '                # water level file name; input file format: write(*,*) eta
lerginp  : F
walvfac  : 1.00000000000000
iwatlvformat : 1
multiple_in  : T
lexport_walv_mod_out : F
export_walv_deltc    : 0.0E+000


#!-----------------------------------------------------------------------
#! Hotfile
#!-----------------------------------------------------------------------

#&HOTFILE
lhotf        : T                  # Write hotfile
filehot_out  : 'wwm_hot_out'      #'.nc' suffix will be added 
begtc        : '20111101.000000'  #Starting time of hotfile writing. With ihot!=0 in SCHISM,
                                  #this will be whatever the new hotstarted time is (even with ihot=2)

deltc        : 21600.             # time between hotfile writes
unitc        : 'SEC'              # unit used above
endtc        : '20111130.000000'  # Ending time of hotfile writing (adjust with BEGTC)
lcyclehot    : F                  # Applies only to netcdf
                                  # If T then hotfile contains 2 last records.
                                  # If F then hotfile contains N record if N outputs have been done

                                  # For binary only one record.
hotstyle_out : 2                  # 1: binary hotfile of data as output
                                  # 2: netcdf hotfile of data as output (default)

multipleout  : 0                  # 0: hotfile in a single file (binary or netcdf), MPI_REDUCE is then used and thus you'd avoid too freq. output 
                                  # 1: hotfiles in separate files, each associated with one process

filehot_in   : 'wwm_hot_in.nc'    # (Full) hot file name for input
hotstyle_in  : 2                  # 1: binary hotfile of data as input
                                  # 2: netcdf hotfile of data as input (default)
ihotpos_in   : 0                  # Position in hotfile (only for netcdf) for reading
multiplein   : 0                  # 0: read hotfile from one single file
                                  # 1: read hotfile from multiple files (must use same # of CPU?)

#!-----------------------------------------------------------------------
#! Source Terms
#!-----------------------------------------------------------------------

#&ENGS !SOURCE TERMS
isource  : 1                      # Source Term Formulation for deep water: 1 ~ Ardhuin et al. (ST4), 2 ~ Janssen et al., (ECMWF, ST2), ~ 3 ~ Komen et al., (SWAN), 4 ~ Babanin et al., Ziegler et al, (ST6, WW3), (DEFAULT: 1)
mesnl    : 1                      # Nonlinear Interaction NL4 , 1 ~ on, 0 ~ off (DIA), (DEFAULT: 1)
mesin    : 1                      # Wind input 1 ~ on, 0 ~ off, (DEFAULT: 1)
ifric    : 1                      # Now only JONSWAP friction will add Roland & Ardhuin soon.
mesbf    : 1                      # Bottomg friction: 1 ~ on, 0 ~ off (JONSWAP Formulation); (DEFAULT: 1)
fricc    : 0.067                  # Cjon - Bottom friction coefficient (always positive); (DEFAULT: 0.067)
mesbr    : 1                      # Shallow water wave breaking; 0: off; 1: on: BJ78 same as in SWAN, (DEFAULT: 1)
icrit    : 1                      # Wave breaking criterion: set as 1 - SWAN, 2 - Dingemans; (DEFAULT: 2) 
ibreak   : 1                      # Now only Battjes & Janssen
alpbj    : 0.5                    # Dissipation proportionality coefficient, (DEFAULT: 0.5)
brhd     : 0.78                   # Wave breaking coefficient for Const. type wave breaking criterion; range: 0.6-1.1 (suggested 0.78)
lmaxetot : T                      # Limit shallow water wave height by wave breaking limiter (default=T)
mesds    : 1                      # Whitecapping 1 ~ on, 0 ~ off; (DEFAULT: 1)
mestr    : 1                      # Nonlinear Interaction in shallow water SNL3: 1 ~ on, 0 ~ off (DEFAULT: 0)
trico    : 0.1                    # proportionality const. (\alpha_EB); default is 0.1; (DEFAULT: 0.1)
trira    : 5.                     # ratio of max. freq. considered in triads over mean freq.; 2.5 is suggested; (DEFAULT: 2.5)
triurs   : 0.1                    # critical Ursell number; if Ursell # < TRIURS; triads are not computed; (DEFAULT: 0.1)



#&SIN4 ! Input parameter for ST4 source terms do not touch or reach our paper about this ...
zwnd        : 10.0000000000000
alpha0      : 9.499999694526196E-003
z0max       : 0.000000000000000E+000
betamax     : 1.54000000000000
sinthp      : 2.00000000000000
zalp        : 6.000000052154064E-003
tauwshelter : 0.300000011920929
swellfpar   : 1.00000000000000
swellf      : 0.660000026226044
swellf2     : -1.799999922513962E-002
swellf3     : 2.199999988079071E-002
swellf4     : 150000.000000000
swellf5     : 1.20000004768372
swellf6     : 0.000000000000000E+000
swellf7     : 360000.000000000
z0rat       : 3.999999910593033E-002
sinbr       : 0.000000000000000E+000


#&SDS4 ! Input parameter for ST4 dissipation terms do not touch or reach our paper about this ...
sdsc1         : 0.000000000000000E+000
fxpm3         : 4.00000000000000
fxfm3         : 2.50000000000000
fxfmage       : 0.000000000000000E+000
sdsc2         : -2.200000017182902E-005
sdscum        : -0.403439998626709
sdsstrain     : 0.000000000000000E+000
sdsc4         : 1.00000000000000
sdsc5         : 0.000000000000000E+000
sdsc6         : 0.300000011920929
sdsbr         : 8.999999845400453E-004
sdsbr2        : 0.800000011920929
sdsp          : 2.00000000000000
sdsiso        : 2.00000000000000
sdsbck        : 0.000000000000000E+000
sdsabk        : 1.50000000000000
sdspbk        : 4.00000000000000
sdsbint       : 0.300000011920929
sdshck        : 1.50000000000000
sdsdth        : 80.0000000000000
sdscos        : 2.00000000000000
sdsbrf1       : 0.500000000000000
sdsbrfdf      : 0.000000000000000E+000
sdsbm0        : 1.00000000000000
sdsbm1        : 0.000000000000000E+000
sdsbm2        : 0.000000000000000E+000
sdsbm3        : 0.000000000000000E+000
sdsbm4        : 0.000000000000000E+000
sdshfgen      : 0.000000000000000E+000
sdslfgen      : 0.000000000000000E+000
whitecapwidth : 0.300000011920929
fxincut       : 0.000000000000000E+000
fxdscut       : 0.000000000000000E+000


#!-----------------------------------------------------------------------
#! Model Numerics
#!-----------------------------------------------------------------------

#&NUMS
icomp : 3           # This parameter controls the way how the splitting is done and whether implicit or explicit schemes are used for spectral advection
                    # ICOMP = 0
                    # This means that all dimensions are integrated using explicit methods. Similar
                    # to WW3, actually the same schemes are available in WW3 4.1.
                    # ICOMP = 1
                    # This mean that advection in geographical space is done using implicit
                    # Methods, source terms and spectral space are still integrated as done in
                    # WW3.
                    # ICOMP = 2
                    # This means that the advection is done using implicit methods and that the
                    # source terms are integrated semi-implicit using Patankar rules and linearized
                    # source terms as done in SWAN. Spectral part is still a fractional step
                    # ICOMP = 3: fully implicit and no splitting

amethod : 7         # AMETHOD controls the different Methods in geographical space
                    # AMETHOD = 0
                    # No Advection in geo. Space
                    # AMETHOD = 1
                    # Explicit N-Scheme for ICOMP = 0 and Implicit N-Scheme for ICOMP > 0
                    # AMETHOD = 2
                    # PSI-Scheme for ICOMP = 0 and Implicit
                    # Crank-Nicholson N-Scheme for ICOMP > 0
                    # AMETHOD = 3
                    # LFPSI Scheme for ICOMP = 0 and Implicit two time level N2 scheme for ICOMP > 0
                    # AMETHOD = 4
                    # Like AMETHOD = 1 but using PETSc based on small matrices MNP**2. this can be efficient on small to medium scale cluster up to say 128 Nodes.
                    # AMETHOD = 5
                    # Like AMETHOD = 1 but using PETSc and assembling the full matrix and the source terms at once (MNP * MDC * MSC)**2. number of equations
                    # this is for large scale applications
                    # Remark for AMETHOD = 4 and 5. This methods are new and only tested on a few cases where the results look reasonable and do not depend on the number of CPU's which
                    # valdiates the correct implementation. The scaling performance is anticipated to be "quite poor" at this time. Many different consituents influence the parallel speedup.
                    # Please let me know all the information you have in order to improve and accelarate the developement of implicit parallel WWM-III.
                    # Have fun ... Aron and Thomas.
                    # AMETHOD = 6 - BCGS Solver 
                    # AMETHOD = 7 - GAUSS and JACOBI SOLVER 

smethod : 1         # This switch controls the way the source terms are integrated. 0: no source terms;
                    # 1: splitting using RK-3 and SI for fast and slow modes 2: semi-implicit;
                    # 3: R-K3 (if ICOMP=0 or 1) - slow; 4: Dynamic Splitting (experimental)

dmethod : 2        # This switch controls the numerical method in directional space.
                   # DMETHOD = 0
                   # No advection in directional space
                   # DMETHOD = 1
                   # Crank-Nicholson (RTHETA = 0.5) or Euler Implicit scheme (RTHETA = 1.0)
                   # DMEHOD = 2
                   # Ultimate Quickest as in WW3 (usually best)
                   # DMETHOD = 3
                   # RK5-WENO
                   # DMETHOD = 4
                   # Explicit FVM Upwind scheme

melim      : 1                  # Source Term Limiter on/off (1/0) default values = 1
litersplit : F                  # T: double Strang split; F: simple split (more efficienct). Default: F

lfilterth  : F                  # LFILTERTH: use a CFL filter to limit the advection vel. In directional space. This is similar to WW3.
                                # Mostly not used. WWMII is always stable.

maxcflth   : 1.0                # Max Cfl in Theta space; used only if LFILTERTH=T

fmethod    : 1                  # This switch controls the numerical method used in freq. space
                                # = 0 No Advection in spectral space
                                # = 1 Ultimate Quickest as in WW3 (best)

lfiltersig : F                  # Limit the advection velocitiy in freq. space (usually F)
maxcflsig  : 1.0                # Max Cfl in freq. space; used only if LFILTERSIG=T
ldifr      : F                  # Use phase decoupled diffraction approximation according to Holthuijsen et al. (2003) (usually T; if crash, use F)
idiffr     : 1                  # Extended WAE accounting for higher order effects WAE becomes nonlinear; 1: Holthuijsen et al. ; 2: Liau et al. ; 3: Toledo et al. (in preparation)
lconv      : F                  # Estimate convergence criterian and write disk (quasi-steady - qstea.out)
lcfl       : F                  # Write out CFL numbers; use F to save time
nqsiter    : 1                  # # of quasi-steady (Q-S) sub-divisions within each WWM time step (trial and errors)
qsconv1    : 0.98               # Number of grid points [%/100] that have to fulfill abs. wave height criteria EPSH1
qsconv2    : 0.98               # Number of grid points [%/100] that have to fulfill rel. wave height criteria EPSH2
qsconv3    : 0.98               # Number of grid points [%/100] that have to fulfill sum. rel. wave action criteria EPSH3
qsconv4    : 0.98               # Number of grid points [%/100] that have to fulfill rel. avg. wave steepness criteria EPSH4
qsconv5    : 0.98               # Number of grid points [%/100] that have to fulfill avg. rel. wave period criteria EPSH5
lexpimp    : F                  # Use implicit schemes for freq. lower than given below by FREQEXP; used only if ICOMP=0
freqexp    : 0.1                # Minimum frequency for explicit schemes; only used if LEXPIMP=T and ICOMP=0
epsh1      : 0.01               # Convergence criteria for rel. wave height ! EPSH1 < CONVK1 = REAL(ABS(HSOLD(IP)-HS2)/HS2)
epsh2      : 0.01               # Convergence criteria for abs. wave height ! EPSH2 < CONVK2 = REAL(ABS(HS2-HSOLD(IP)))
epsh3      : 0.01               # Convergence criteria for the rel. sum of wave action ! EPSH3 < CONVK3 = REAL(ABS(SUMACOLD(IP)-SUMAC)/SUMAC)
epsh4      : 0.01               # Convergence criteria for the rel. avg. wave steepness criteria ! EPSH4 < CONVK4 = REAL(ABS(KHS2-KHSOLD(IP))/KHSOLD(IP))
epsh5      : 0.01               # Convergence criteria for the rel. avg. waveperiod ! EPSH5 < REAL(ABS(TM02-TM02OLD(IP))/TM02OLD(IP))
lvector    : F                  # Use optmized propagation routines for large high performance computers e.g. at least more than 128 CPU. Try LVECTOR=F first.

ivector    : 2                  # USed if LVECTOR=T; Different flavours of communications
                                # LVECTOR = 1; same propagation style as if LVECTOR = F, this is for testing and development
                                # LVECTOR = 2; all spectral bins are propagated with the same time step and communications is done only once per sub-iteration
                                # LVECTOR = 3; all directions with the same freq. are propgated using the same time step the communications is done for each freq.
                                # LVECTOR = 4; 2 but for mixed open-mpi, code has to be compiled with -openmp
                                # LVECTOR = 5; 3 but for mixed open-mpi, code has to be compiled with -openmp
                                # LVECTOR = 6; same as 2 but highly optmizied with respect to memory usage, of course it is must less efficient than 2
                                # remarks: if you are using this routines be aware that the memory amount that is used is approx. for LVECTOR 1-5 arround
                                # 24 * MSC * MDC * MNP, so if you are trying this on 1 CPU you get a segmentation fault if your system has not enough memory or
                                # if your system is not properly configured it may results into the fact that your computer starts blocking since it try's to swap to disk
                                # The total amount of memoery used per CPU = 24 * MSC * MDC * MNP / No.CPU

ladvtest      : F           # for testing the advection schemes, testcase will be added soon
lchkconv      : F           # needs to set to .true. for quasi-steady mode. in order to compute the QSCONVi criteria and check them
dtmin_dyn     : 1.          # min. time step (sec?) for dynamic integration, this controls in SMETHOD the smallest time step for the triads, DT = 1.s is found to work well. 
ndyniter      : 100         # max. iteration for dyn. scheme afterwards the limiter is applied in the last step, for SMETHOD .eq. this controls the integration of the triad interaction terms, which is done dynamically. 
dtmin_sin     : 1.          # min. time steps for the full fractional step method, where each source term is integrated with its own fractional step
dtmin_snl4    : 1.      
dtmin_sds     : 1.      
dtmin_snl3    : 1.     
dtmin_sbr     : 0.10    
dtmin_sbf     : 1.0     
ndyniter_sin  : 10          # max. iterations for each source term in the fractional step approach. 
ndyniter_snl4 : 10
ndyniter_sds  : 10
ndyniter_sbr  : 10
ndyniter_snl3 : 10 
ndyniter_sbf  : 10

zeta_meth : 0                   # 0: use a simple conjugate gradient
                                #    preconditioner
                                # 1: use PETSC

wae_solverthr      : 1.e-9     # Threshold for the Block-Jacobi or Block-Gauss-Seider solver
maxiter            : 100       # Max. number of iterations
pmin               : 1.        # Max. percentage of non-converged grid points
lnaninfchk         : F         # Check for NaN and INF; usually turned off for efficiency
lzeta_setup        : F         # Compute wave setup (simple momentum eq.)
zeta_meth          : 0         # Method for wave setup  Mathieu please explain!
block_gauss_seidel : T         # Use the Gauss Seidel on each computer block. The result seems to be faster and use less memory But the # of iterations depends on the number of processors
lnonl              : F         # Solve the nonlinear system using simpler algorithm (Patankar)
aspar_local_level  : 0         # Aspar locality level (0-10; check with your system) 

l_solver_norm      : F         # Compute solver norm ||A*x-b|| as termination
                               # check of jacobi-Gauss-Seidel solver. Will increas cost if T


#!-----------------------------------------------------------------------
#! Nesting parameters
#!-----------------------------------------------------------------------

#&NESTING
l_nesting       : F    # whether to produce nesting data or not
l_hotfile       : F    # whether to produce an hotfile as output
l_bouc_param    : F    # whether to produce a parametric boundary condition to be used by the nested grids
l_bouc_spec     : F    # whether to produce a spectral boundary condition to be used by the nested grids
nb_grid_nest    : 0    # number of nested grids. All lines below must contain NB_GRID_NEST entries.
#!listigridtype :      # list of integers giving the type of nested grid
#!listfilegrid  :      # list of strings for the grid file names.
#!listfilebound :      # list of boundary file names to be used
#!listbegtc     :      # list of beginning time of the runs (used for hotfile and boundary)
#!listdeltc     :      # list of DELTC of the boundary output
#!listunitc     :      # list of UNITS of the boundary output
#!listendtc     :      # list of ENDTC of the boundary output
#!listprefix    :      # list of prefix used for the output variable



#!-----------------------------------------------------------------------
#! PETSc Options
#!-----------------------------------------------------------------------

#! only used with AMETHOD 4 or 5
#&PETScOptions
# Summary of Sparse Linear Solvers Available from PETSc: http://www.mcs.anl.gov/petsc/documentation/linearsolvertable.html

ksptype : 'LGMRES'         # This parameter controls which solver is used. This is the same as petsc command line parameter -ksp_type.
                           # KSPTYPE = 'GMRES', Implements the Generalized Minimal Residual method. (Saad and Schultz, 1986) with restart
                           # KSPTYPE = 'LGMRES', Augments the standard GMRES approximation space with approximations to the error from previous restart cycles.
                           # KSPTYPE = 'DGMRES', In this implementation, the adaptive strategy allows to switch to the deflated GMRES when the stagnation occurs.
                           # KSPTYPE = 'PGMRES', Implements the Pipelined Generalized Minimal Residual method. Only PETSc 3.3
                           # KSPTYPE = 'KSPBCGSL', Implements a slight variant of the Enhanced BiCGStab(L) algorithm

rtol     : 1.E-20      # the relative convergence tolerance (relative decrease in the residual norm)
abstol   : 1.E-20      # the absolute convergence tolerance (absolute size of the residual norm)
dtol     : 10000.      # the divergence tolerance
maxits   : 1000        # maximum number of iterations to use
initialguessnonzero : F        # Tells the iterative solver that the initial guess is nonzero; otherwise KSP assumes the initial guess is to be zero
gmrespreallocate    : T        # Causes GMRES and FGMRES to preallocate all its needed work vectors at initial setup rather than the default, which is to allocate them in chunks when needed.

pctype : 'SOR'             # This parameter controls which  preconditioner is used. This is the same as petsc command line parameter -pc_type
                           # PCTYPE = 'SOR', (S)SOR (successive over relaxation, Gauss-Seidel) preconditioning
                           # PCTYPE = 'ASM', Use the (restricted) additive Schwarz method, each block is (approximately) solved with its own KSP object.
                           # PCTYPE = 'HYPRE', Allows you to use the matrix element based preconditioners in the LLNL package hypre
                           # PCTYPE = 'SPAI', Use the Sparse Approximate Inverse method of Grote and Barnard as a preconditioner
# PCTYPE = 'NONE', This is used when you wish to employ a nonpreconditioned Krylov method.